\documentclass[tikz,14pt,fleqn]{article}

\input{headers.sty}


\usepackage[utf8]{inputenc}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% VARIABLES
\newcommand\namesurname{Albert Cerfeda}
\newcommand\assignment{Assignment 1 - Linear Regression}

\newcommand\subject{Machine Learning}
\newcommand\documentdate{27 April 2023}

% Title content
%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\rhead{\assignment}
\lhead{\namesurname}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\rfoot{Page \thepage}


\begin{document}

\begin{titlepage}
   \begin{center}
       \vspace*{0.2cm}

       \textbf{\Large{\subject}}

       \vspace{0.5cm}
        \textbf{\assignment}\\[5mm]
        
            
       \vspace{0.4cm}

        \namesurname
        \begin{figure}[H]
            \centering
        \end{figure}
       \tableofcontents

       \vspace*{\fill}
     
        \includegraphics[width=0.4\textwidth]{fig/logo.png}
       
        \documentdate \\
        Universit√† della Svizzera italiana\\
        Faculty of Informatics\\
        Switzerland\\

   \end{center}
\end{titlepage}


\section{Tasks}

This section should contain a detailed description of how you solved the assignment, including all required statistical analyses of the models' performance and a comparison between the linear regression and the model of your choice. Limit the assignment to 8-10 pages and do not include any code in the report.

\subsection{Task 1}
Use the family of models $f(\mathbf{x}, \boldsymbol{\theta}) = \theta_0 + \theta_1 \cdot x_1 + \theta_2 \cdot x_2 + \theta_3 \cdot \sin(x_2) + \theta_4 \cdot x_1 \cdot x_2$ to fit the data. 

\begin{itemize}
	\item [a.] Write in the report the formula of the model substituting parameters $\theta_0, \ldots, \theta_4$ with the estimates you've found:
	$$f(\mathbf{x}, \boldsymbol{\theta}) = \_ + \_ \cdot x_1 + \_ \cdot x_2 + \_ \cdot \sin(x_2) + \_ \cdot x_1 \cdot x_2$$
	\item [b.] Evaluate the test performance of your model using the mean squared error as performance measure.
\end{itemize}


\subsection{Task 2}
Consider any family of non-linear models of your choice to address the above regression problem.
\begin{itemize}
	\item [a.] Evaluate the test performance of your model using the mean squared error as performance measure. 
	\item [b.] Compare your model with the linear regression of Task 1. Which one is {statistically} better?
\end{itemize}

\subsection{Task 3 (Bonus)}
In the \href{https://github.com/GiorgiaAuroraAdorni/ML-bachelor-course-assignments-sp23}{\textbf{GitHub repository of the course}}, you will find a trained Scikit-learn model that we built using the same dataset you are given. 
This \textit{baseline} model is able to achieve a MSE of \textbf{0.022}, when evaluated on the test set. 
You will get extra points if you provide a model of your choice whose test performance is \textbf{better} (i.e., the MSE is lower) than ours. Of course, you must also tell us why your model is performing better.

%----------------------------------------------------------------------------------------
%	Questions
%----------------------------------------------------------------------------------------
%\newpage
\section{Questions}

\subsection{Q1. Training versus Validation}
\begin{itemize}
\item[Q1.1] What is the whole figure about?  
\item[A1.1] ~\\

\item[Q1.2] Explain the behaviours of the curves in each of the three highlighted sections in the figure, namely (a), (b), and (c).   
\item[A1.2] ~\\

\begin{itemize}
\item[Q1.2.a] Can you identify any signs of overfitting or underfitting in the plot? If yes, explain which sections correspond to which concept.
\item[A1.2.a] ~\\

\item[Q1.2.b] How can you determine the optimal complexity of the model based on the given plot?
\item[A1.2.b] ~\\
\end{itemize}
	
\item[Q1.3] Is there any evidence of high approximation risk? Why? If yes, in which of the below subfigures?  
\item[A1.3] ~\\

\item[Q1.4] Do you think that increasing the model complexity can bring the training error to zero? And the structural risk?  
\item[A1.4] ~\\

\item[Q1.5] If the X axis represented the training iterations instead, would you think that the training procedure that generated the figure used early stopping? Explain why. (\textbf{NB:} ignore the subfigures and the dashed vertical lines)
\item[A1.5] ~\\

\end{itemize}

\subsection{Q2. Linear Regression}
Comment and compare how the (a.) training error, (b.) test error and (c.) coefficients would change in the following cases:
\begin{itemize}
\item[Q2.1] $x_3 = x_1 + 0.2 \cdot x_2$.
\item[A2.1] ~\\

\item[Q2.2] $x_3 = x_1 \cdot x_2 \cdot x_2$
\item[A2.2] ~\\

\item[Q2.3] $x_3$ is a random variable independent from $y$.
\item[A2.3] ~\\

\item[Q2.3] How would your answers change if you were using Lasso Regression?
\item[A2.3] ~\\

\item[Q2.4] Explain the motivation behind Ridge and Lasso regression and their principal differences.
\item[A2.4] ~\\  
\end{itemize}

\subsection{Q3. Classification}
\begin{itemize}
\item[Q3.1] Your boss asked you to solve the problem using a perceptron, and now he's upset because you are getting poor results. How would you justify the poor performance of your perceptron classifier to your boss?
\item[A3.1] ~\\

\item[Q3.2] Would you expect better luck with a neural network with the activation function $h(x) = - x * e^(-2)$ for the hidden units?
\item[A3.2] ~\\

\item[Q3.3] What are the main differences and similarities between the perceptron and the logistic regression neuron?
\item[A3.3] ~\\

\end{itemize}


\end{document}